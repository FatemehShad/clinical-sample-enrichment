{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b8e4b5-3946-4a2d-bb6b-cb018571f7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe8535b0-0ac1-4280-909f-4f5e750de4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\t\t\t<script type=\"text/javascript\">\n",
       "\t\t\t<!--\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_script');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('script');\n",
       "\t\t\t\telement.type = 'text/javascript';\n",
       "\t\t\t\telement.innerHTML = 'function NetworKit_pageEmbed(id) { var i, j; var elements; elements = document.getElementById(id).getElementsByClassName(\"Plot\"); for (i=0; i<elements.length; i++) { elements[i].id = id + \"_Plot_\" + i; var data = elements[i].getAttribute(\"data-image\").split(\"|\"); elements[i].removeAttribute(\"data-image\"); var content = \"<div class=\\\\\"Image\\\\\" id=\\\\\"\" + elements[i].id + \"_Image\\\\\" />\"; elements[i].innerHTML = content; elements[i].setAttribute(\"data-image-index\", 0); elements[i].setAttribute(\"data-image-length\", data.length); for (j=0; j<data.length; j++) { elements[i].setAttribute(\"data-image-\" + j, data[j]); } NetworKit_plotUpdate(elements[i]); elements[i].onclick = function (e) { NetworKit_overlayShow((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"HeatCell\"); for (i=0; i<elements.length; i++) { var data = parseFloat(elements[i].getAttribute(\"data-heat\")); var color = \"#00FF00\"; if (data <= 1 && data > 0) { color = \"hsla(0, 100%, 75%, \" + (data) + \")\"; } else if (data <= 0 && data >= -1) { color = \"hsla(240, 100%, 75%, \" + (-data) + \")\"; } elements[i].style.backgroundColor = color; } elements = document.getElementById(id).getElementsByClassName(\"Details\"); for (i=0; i<elements.length; i++) { elements[i].setAttribute(\"data-title\", \"-\"); NetworKit_toggleDetails(elements[i]); elements[i].onclick = function (e) { NetworKit_toggleDetails((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"MathValue\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"nan\") { elements[i].parentNode.innerHTML = \"\" } } elements = document.getElementById(id).getElementsByClassName(\"SubCategory\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } elements = document.getElementById(id).getElementsByClassName(\"Category\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } var isFirefox = false; try { isFirefox = typeof InstallTrigger !== \"undefined\"; } catch (e) {} if (!isFirefox) { alert(\"Currently the function\\'s output is only fully supported by Firefox.\"); } } function NetworKit_plotUpdate(source) { var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(source.id + \"_Image\"); image.style.backgroundImage = \"url(\" + data + \")\"; } function NetworKit_showElement(id, show) { var element = document.getElementById(id); element.style.display = (show) ? \"block\" : \"none\"; } function NetworKit_overlayShow(source) { NetworKit_overlayUpdate(source); NetworKit_showElement(\"NetworKit_Overlay\", true); } function NetworKit_overlayUpdate(source) { document.getElementById(\"NetworKit_Overlay_Title\").innerHTML = source.title; var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(\"NetworKit_Overlay_Image\"); image.setAttribute(\"data-id\", source.id); image.style.backgroundImage = \"url(\" + data + \")\"; var link = document.getElementById(\"NetworKit_Overlay_Toolbar_Bottom_Save\"); link.href = data; link.download = source.title + \".svg\"; } function NetworKit_overlayImageShift(delta) { var image = document.getElementById(\"NetworKit_Overlay_Image\"); var source = document.getElementById(image.getAttribute(\"data-id\")); var index = parseInt(source.getAttribute(\"data-image-index\")); var length = parseInt(source.getAttribute(\"data-image-length\")); var index = (index+delta) % length; if (index < 0) { index = length + index; } source.setAttribute(\"data-image-index\", index); NetworKit_overlayUpdate(source); } function NetworKit_toggleDetails(source) { var childs = source.children; var show = false; if (source.getAttribute(\"data-title\") == \"-\") { source.setAttribute(\"data-title\", \"+\"); show = false; } else { source.setAttribute(\"data-title\", \"-\"); show = true; } for (i=0; i<childs.length; i++) { if (show) { childs[i].style.display = \"block\"; } else { childs[i].style.display = \"none\"; } } }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_script');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_style');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('style');\n",
       "\t\t\t\telement.type = 'text/css';\n",
       "\t\t\t\telement.innerHTML = '.NetworKit_Page { font-family: Arial, Helvetica, sans-serif; font-size: 14px; } .NetworKit_Page .Value:before { font-family: Arial, Helvetica, sans-serif; font-size: 1.05em; content: attr(data-title) \":\"; margin-left: -2.5em; padding-right: 0.5em; } .NetworKit_Page .Details .Value:before { display: block; } .NetworKit_Page .Value { font-family: monospace; white-space: pre; padding-left: 2.5em; white-space: -moz-pre-wrap !important; white-space: -pre-wrap; white-space: -o-pre-wrap; white-space: pre-wrap; word-wrap: break-word; tab-size: 4; -moz-tab-size: 4; } .NetworKit_Page .Category { clear: both; padding-left: 1em; margin-bottom: 1.5em; } .NetworKit_Page .Category:before { content: attr(data-title); font-size: 1.75em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory { margin-bottom: 1.5em; padding-left: 1em; } .NetworKit_Page .SubCategory:before { font-size: 1.6em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory[data-title]:before { content: attr(data-title); } .NetworKit_Page .Block { display: block; } .NetworKit_Page .Block:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .Block .Thumbnail_Overview, .NetworKit_Page .Block .Thumbnail_ScatterPlot { width: 260px; float: left; } .NetworKit_Page .Block .Thumbnail_Overview img, .NetworKit_Page .Block .Thumbnail_ScatterPlot img { width: 260px; } .NetworKit_Page .Block .Thumbnail_Overview:before, .NetworKit_Page .Block .Thumbnail_ScatterPlot:before { display: block; text-align: center; font-weight: bold; } .NetworKit_Page .Block .Thumbnail_Overview:before { content: attr(data-title); } .NetworKit_Page .HeatCell { font-family: \"Courier New\", Courier, monospace; cursor: pointer; } .NetworKit_Page .HeatCell, .NetworKit_Page .HeatCellName { display: inline; padding: 0.1em; margin-right: 2px; background-color: #FFFFFF } .NetworKit_Page .HeatCellName { margin-left: 0.25em; } .NetworKit_Page .HeatCell:before { content: attr(data-heat); display: inline-block; color: #000000; width: 4em; text-align: center; } .NetworKit_Page .Measure { clear: both; } .NetworKit_Page .Measure .Details { cursor: pointer; } .NetworKit_Page .Measure .Details:before { content: \"[\" attr(data-title) \"]\"; display: block; } .NetworKit_Page .Measure .Details .Value { border-left: 1px dotted black; margin-left: 0.4em; padding-left: 3.5em; pointer-events: none; } .NetworKit_Page .Measure .Details .Spacer:before { content: \".\"; opacity: 0.0; pointer-events: none; } .NetworKit_Page .Measure .Plot { width: 440px; height: 440px; cursor: pointer; float: left; margin-left: -0.9em; margin-right: 20px; } .NetworKit_Page .Measure .Plot .Image { background-repeat: no-repeat; background-position: center center; background-size: contain; height: 100%; pointer-events: none; } .NetworKit_Page .Measure .Stat { width: 500px; float: left; } .NetworKit_Page .Measure .Stat .Group { padding-left: 1.25em; margin-bottom: 0.75em; } .NetworKit_Page .Measure .Stat .Group .Title { font-size: 1.1em; display: block; margin-bottom: 0.3em; margin-left: -0.75em; border-right-style: dotted; border-right-width: 1px; border-bottom-style: dotted; border-bottom-width: 1px; background-color: #D0D0D0; padding-left: 0.2em; } .NetworKit_Page .Measure .Stat .Group .List { -webkit-column-count: 3; -moz-column-count: 3; column-count: 3; } .NetworKit_Page .Measure .Stat .Group .List .Entry { position: relative; line-height: 1.75em; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:before { position: absolute; left: 0; top: -40px; background-color: #808080; color: #ffffff; height: 30px; line-height: 30px; border-radius: 5px; padding: 0 15px; content: attr(data-tooltip); white-space: nowrap; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:after { position: absolute; left: 15px; top: -10px; border-top: 7px solid #808080; border-left: 7px solid transparent; border-right: 7px solid transparent; content: \"\"; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:after, .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:before { display: block; } .NetworKit_Page .Measure .Stat .Group .List .Entry .MathValue { font-family: \"Courier New\", Courier, monospace; } .NetworKit_Page .Measure:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .PartitionPie { clear: both; } .NetworKit_Page .PartitionPie img { width: 600px; } #NetworKit_Overlay { left: 0px; top: 0px; display: none; position: absolute; width: 100%; height: 100%; background-color: rgba(0,0,0,0.6); z-index: 1000; } #NetworKit_Overlay_Title { position: absolute; color: white; transform: rotate(-90deg); width: 32em; height: 32em; padding-right: 0.5em; padding-top: 0.5em; text-align: right; font-size: 40px; } #NetworKit_Overlay .button { background: white; cursor: pointer; } #NetworKit_Overlay .button:before { size: 13px; display: inline-block; text-align: center; margin-top: 0.5em; margin-bottom: 0.5em; width: 1.5em; height: 1.5em; } #NetworKit_Overlay .icon-close:before { content: \"X\"; } #NetworKit_Overlay .icon-previous:before { content: \"P\"; } #NetworKit_Overlay .icon-next:before { content: \"N\"; } #NetworKit_Overlay .icon-save:before { content: \"S\"; } #NetworKit_Overlay_Toolbar_Top, #NetworKit_Overlay_Toolbar_Bottom { position: absolute; width: 40px; right: 13px; text-align: right; z-index: 1100; } #NetworKit_Overlay_Toolbar_Top { top: 0.5em; } #NetworKit_Overlay_Toolbar_Bottom { Bottom: 0.5em; } #NetworKit_Overlay_ImageContainer { position: absolute; top: 5%; left: 5%; height: 90%; width: 90%; background-repeat: no-repeat; background-position: center center; background-size: contain; } #NetworKit_Overlay_Image { height: 100%; width: 100%; background-repeat: no-repeat; background-position: center center; background-size: contain; }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_style');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_Overlay');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('div');\n",
       "\t\t\t\telement.innerHTML = '<div id=\"NetworKit_Overlay_Toolbar_Top\"><div class=\"button icon-close\" id=\"NetworKit_Overlay_Close\" /></div><div id=\"NetworKit_Overlay_Title\" /> <div id=\"NetworKit_Overlay_ImageContainer\"> <div id=\"NetworKit_Overlay_Image\" /> </div> <div id=\"NetworKit_Overlay_Toolbar_Bottom\"> <div class=\"button icon-previous\" onclick=\"NetworKit_overlayImageShift(-1)\" /> <div class=\"button icon-next\" onclick=\"NetworKit_overlayImageShift(1)\" /> <a id=\"NetworKit_Overlay_Toolbar_Bottom_Save\"><div class=\"button icon-save\" /></a> </div>';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_Overlay');\n",
       "\t\t\t\tdocument.body.appendChild(element);\n",
       "\t\t\t\tdocument.getElementById('NetworKit_Overlay_Close').onclick = function (e) {\n",
       "\t\t\t\t\tdocument.getElementById('NetworKit_Overlay').style.display = 'none';\n",
       "\t\t\t\t}\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t-->\n",
       "\t\t\t</script>\n",
       "\t\t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from littleballoffur import RandomWalkWithRestartSampler\n",
    "from littleballoffur import ForestFireSampler\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, GAE\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.loader import ClusterData\n",
    "from torch_geometric.loader import ClusterLoader\n",
    "from sklearn.decomposition import NMF\n",
    "from numpy.linalg import svd\n",
    "import pickle\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "\n",
    "# class GCNEncoder(torch.nn.Module):\n",
    "#         def __init__(self, in_channels, out_channels):\n",
    "#             super(GCNEncoder, self).__init__()\n",
    "#             self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "#             self.conv2 = GCNConv(2 * out_channels, out_channels)\n",
    "    \n",
    "#         def forward(self, x, edge_index):\n",
    "#             x = torch.relu(self.conv1(x, edge_index))\n",
    "#             x = torch.dropout(x, p=0.2, train=self.training)\n",
    "#             x = self.conv2(x, edge_index)\n",
    "#             return x\n",
    "\n",
    "# class GCNEncoder(torch.nn.Module):\n",
    "#     def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "#         super(GCNEncoder, self).__init__()\n",
    "#         self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "#         self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "#     def forward(self, x, edge_index):\n",
    "#         x = F.relu(self.conv1(x, edge_index))\n",
    "#         x = torch.dropout(x, p=0.2, train=self.training)\n",
    "#         x = F.relu(self.conv2(x, edge_index))\n",
    "#         return x\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, BatchNorm\n",
    "import scipy.sparse as sp\n",
    "\n",
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        self.batch_norms = torch.nn.ModuleList()\n",
    "\n",
    "\n",
    "        # First layer\n",
    "        self.layers.append(GCNConv(in_channels, hidden_channels))\n",
    "        self.batch_norms.append(BatchNorm(hidden_channels))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.layers.append(GCNConv(hidden_channels, hidden_channels))\n",
    "            self.batch_norms.append(BatchNorm(hidden_channels))\n",
    "\n",
    "        # Output layer\n",
    "        self.layers.append(GCNConv(hidden_channels, out_channels))\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            x = F.relu(self.batch_norms[i](self.layers[i](x, edge_index)))\n",
    "            x = F.dropout(x, p=0.2, training=self.training)\n",
    "            \n",
    "        x = F.relu(self.layers[-1](x, edge_index))\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "class GAEPipeline:\n",
    "    def __init__(self, in_channels, out_channels, sampling_method='method1', preprocessing=True):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.sampling_method_name = sampling_method\n",
    "        self.sampling_method = self._get_sampling_method(sampling_method)\n",
    "        self.preprocessing = preprocessing\n",
    "        self.encoder = GCNEncoder(in_channels, 64, out_channels, 1).to(self.device)\n",
    "        self.model = GAE(self.encoder).to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.01)\n",
    "\n",
    "    def recon_loss(self, predicted_adj, true_adj):\n",
    "        loss = F.binary_cross_entropy(predicted_adj, true_adj)\n",
    "        return loss\n",
    "\n",
    "    def load_graph_from_pickle(self, file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    def _get_sampling_method(self, method_name):\n",
    "        \"\"\"Dynamically selects the sampling method.\"\"\"\n",
    "        if method_name == 'random_walk':\n",
    "            return self.random_walk\n",
    "        elif method_name == 'forest_fire':\n",
    "            return self.forest_fire\n",
    "        elif method_name == 'clusterGCN':\n",
    "            return self.cluster_GCN\n",
    "        else:\n",
    "            raise ValueError(\"Unknown sampling method\")\n",
    "\n",
    "    def convert_node_labels_to_integers(self, graph):\n",
    "        \"\"\"\n",
    "        Convert the node labels of a NetworkX graph to integers.\n",
    "        \n",
    "        Parameters:\n",
    "        - graph: NetworkX graph with any type of node labels.\n",
    "        \n",
    "        Returns:\n",
    "        - A new NetworkX graph with node labels converted to integers.\n",
    "        \"\"\"\n",
    "        # Create a mapping from old labels to new ones (integers)\n",
    "        mapping = {node: i for i, node in enumerate(graph.nodes())}\n",
    "        # Use relabel_nodes to create a new graph with integer labels\n",
    "        graph_int_labels = nx.relabel_nodes(graph, mapping)\n",
    "        \n",
    "        return graph_int_labels\n",
    "\n",
    "    def preprocess_features(self, features):\n",
    "        # Convert features to a numeric format, handle non-numeric cases\n",
    "        processed_features = []\n",
    "        for feature in features:\n",
    "            try:\n",
    "                # convert the features to float\n",
    "                processed_features.append(float(feature))\n",
    "            except ValueError:\n",
    "                # Handle non-numeric feature (could implement encoding here)\n",
    "                processed_features.append(0.0)  # Using 0.0 as a placeholder\n",
    "        return processed_features\n",
    "\n",
    "    def normalize_features(self, features):\n",
    "        features = np.array(features)\n",
    "        mean = features.mean(axis=0, keepdims=True)\n",
    "        std = features.std(axis=0, keepdims=True)\n",
    "        # Avoid division by zero\n",
    "        std[std == 0] = 1\n",
    "        normalized_features = (features - mean) / std\n",
    "        return normalized_features.tolist()\n",
    "\n",
    "    def from_networkx_to_torch_geometric(self, G):\n",
    "        # Convert node indices to a continuous range\n",
    "        mapping = {k: i for i, k in enumerate(G.nodes())}\n",
    "        edges = torch.tensor([list(map(mapping.get, edge)) for edge in G.edges()], dtype=torch.long).t().contiguous()\n",
    "\n",
    "        if G.nodes():\n",
    "            # Extract a sample node to get feature keys (assumes at least one node exists)\n",
    "            sample_features = next(iter(G.nodes(data=True)))[1]\n",
    "            feature_keys = list(sample_features.keys())\n",
    "            \n",
    "            # Extract and preprocess features for all nodes\n",
    "            features = []\n",
    "            for _, node_features in G.nodes(data=True):\n",
    "                node_feature_values = [node_features.get(key, 0) for key in feature_keys]\n",
    "                processed_features = self.preprocess_features(node_feature_values)\n",
    "                features.append(processed_features)\n",
    "            \n",
    "            # Normalize features\n",
    "            features = self.normalize_features(features)\n",
    "        else:\n",
    "            # Default to a single feature of 0 if no nodes or features\n",
    "            features = [[0]]\n",
    "    \n",
    "        # Convert features to a tensor\n",
    "        x = torch.tensor(features, dtype=torch.float)\n",
    "\n",
    "        # adj_matrix = nx.to_numpy_array(G, nodelist=sorted(G.nodes(), key=lambda x: mapping[x]))\n",
    "        # adj_tensor = torch.tensor(adj_matrix, dtype=torch.float)\n",
    "        \n",
    "        # Create the Data object\n",
    "        # data = Data(x=x, edge_index=edges, adj=adj_tensor)\n",
    "        data = Data(x=x, edge_index=edges)\n",
    "        return data.to(self.device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def random_walk(self, graph):\n",
    "        graph = self.convert_node_labels_to_integers(graph)\n",
    "        model = RandomWalkWithRestartSampler(20000)\n",
    "        new_graph = model.sample(graph)\n",
    "        return new_graph\n",
    "\n",
    "    def forest_fire(self, graph):\n",
    "        graph = self.convert_node_labels_to_integers(graph)\n",
    "        model = ForestFireSampler(10000)\n",
    "        new_graph = model.sample(graph)\n",
    "        return new_graph\n",
    "\n",
    "    def cluster_GCN(self, data):\n",
    "        # Implement your third graph sampling algorithm here\n",
    "\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        # data = data.to(device)\n",
    "        torch.manual_seed(12345)\n",
    "        # Prepare cluster data\n",
    "        cluster_data = ClusterData(data, num_parts=8) \n",
    "        # Create a loader to iterate over clusters\n",
    "        loader = ClusterLoader(cluster_data, batch_size=16, shuffle=True)  \n",
    "        \n",
    "        print()\n",
    "        total_num_nodes = 0\n",
    "        for step, sub_data in enumerate(loader):\n",
    "            print(f'Step {step + 1}:')\n",
    "            print('=======')\n",
    "            print(f'Number of nodes in the current batch: {sub_data.num_nodes}')\n",
    "            print(sub_data)\n",
    "            print()\n",
    "            total_num_nodes += sub_data.num_nodes\n",
    "        \n",
    "        print(f'Iterated over {total_num_nodes} of {data.num_nodes} nodes!')\n",
    "        \n",
    "        return loader\n",
    "\n",
    "    \n",
    "\n",
    "    def preprocess_graph(self, graph):\n",
    "        data = self.from_networkx_to_torch_geometric(graph)\n",
    "        return data\n",
    "\n",
    "    def train(self, graph, epochs=100):\n",
    "        # Preprocessing\n",
    "\n",
    "        \n",
    "        # Graph Sampling\n",
    "        sampled_subgraph = self.sampling_method(graph)\n",
    "\n",
    "        if self.preprocessing:\n",
    "            data = self.preprocess_graph(graph).to(self.device)\n",
    "            \n",
    "        # data.adj = (data.adj > 0).float()\n",
    "        # data = Data(edge_index=sampled_subgraph.edge_index, x=sampled_subgraph.x)\n",
    "        \n",
    "        # Model Training\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            self.optimizer.zero_grad()\n",
    "            z = self.model.encode(data.x, data.edge_index)\n",
    "            # adj_recon = self.model.decoder.forward_all(z) \n",
    "            # loss = self.recon_loss(adj_recon, data.adj)\n",
    "            # recon = self.model.decoder(z, data.edge_index, sigmoid=True)\n",
    "            loss = self.model.recon_loss(z, data.edge_index)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "            # print(f'Epoch {epoch+1}, adj_recon: {adj_recon}')\n",
    "            \n",
    "        torch.save(z, f'{self.sampling_method_name}_embedding.pt')\n",
    "\n",
    "\n",
    "    def train_clusterGCN(self, graph, epochs=500):\n",
    "        # Preprocessing\n",
    "        data = self.preprocess_graph(graph).to(self.device)\n",
    "        # data.adj = (data.adj > 0).float()\n",
    "        \n",
    "        # Graph Sampling\n",
    "        loader = self.cluster_GCN(data)\n",
    "\n",
    "\n",
    "        # optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "        criterion = torch.nn.BCELoss() \n",
    "        final_embeddings = []\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):  \n",
    "            total_loss = 0\n",
    "            epoch_embeddings = [] \n",
    "            for batch_idx, batch_data in enumerate(loader):\n",
    "                batch_data = batch_data.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                z = self.model.encode(batch_data.x, batch_data.edge_index)\n",
    "                loss = self.model.recon_loss(z, batch_data.edge_index)\n",
    "                # recon = self.model.decoder.forward(z, cluster.edge_index, sigmoid=True)\n",
    "                # adj_recon = self.model.decoder(z, cluster.edge_index)\n",
    "                # loss = F.binary_cross_entropy_with_logits(z, adj_recon)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                epoch_embeddings.append(z.detach().cpu().numpy())  # Collect embeddings\n",
    "        \n",
    "                total_loss += loss.item()\n",
    "            avg_loss = total_loss / len(loader)\n",
    "            print(f\"Epoch {epoch+1}, Average Loss: {loss.item()}\")\n",
    "            if epoch == epochs - 1:\n",
    "                final_embeddings = np.concatenate(epoch_embeddings, axis=0)\n",
    "            \n",
    "                \n",
    "        torch.save(torch.from_numpy(final_embeddings), f'{self.sampling_method_name}_embedding.pt')\n",
    "\n",
    "\n",
    "    def non_negative_matrix_factorization(self, graph):\n",
    "        subgraph = self.sampling_method(graph)\n",
    "        \n",
    "        A = nx.to_numpy_array(subgraph)\n",
    "        print(A.shape)\n",
    "        model = NMF(n_components=2, init='random', random_state=0)\n",
    "        \n",
    "        # Fit the model to the adjacency matrix and transform\n",
    "        W = model.fit_transform(A)  # Basis matrix (features)\n",
    "        H = model.components_  # Coefficient matrix (components)\n",
    "        return W, H\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc4b07b8-798d-4f31-975c-b3a7173a21b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m GAEPipeline(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m11\u001b[39m, out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, sampling_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_walk\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m graph \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mload_graph_from_pickle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_graph.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 255\u001b[0m, in \u001b[0;36mGAEPipeline.train\u001b[0;34m(self, graph, epochs)\u001b[0m\n\u001b[1;32m    251\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mencode(data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# adj_recon = self.model.decoder.forward_all(z) \u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# loss = self.recon_loss(adj_recon, data.adj)\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# recon = self.model.decoder(z, data.edge_index, sigmoid=True)\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecon_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/GNNenv/lib/python3.8/site-packages/torch_geometric/nn/models/autoencoder.py:109\u001b[0m, in \u001b[0;36mGAE.recon_loss\u001b[0;34m(self, z, pos_edge_index, neg_edge_index)\u001b[0m\n\u001b[1;32m    105\u001b[0m pos_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlog(\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(z, pos_edge_index, sigmoid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m EPS)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m neg_edge_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m     neg_edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mnegative_sampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_edge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m neg_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m\n\u001b[1;32m    111\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(z, neg_edge_index, sigmoid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    112\u001b[0m                       EPS)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pos_loss \u001b[38;5;241m+\u001b[39m neg_loss\n",
      "File \u001b[0;32m~/anaconda3/envs/GNNenv/lib/python3.8/site-packages/torch_geometric/utils/_negative_sampling.py:102\u001b[0m, in \u001b[0;36mnegative_sampling\u001b[0;34m(edge_index, num_nodes, num_neg_samples, method, force_undirected)\u001b[0m\n\u001b[1;32m    100\u001b[0m idx \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):  \u001b[38;5;66;03m# Number of tries to sample negative indices.\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     rnd \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misin(rnd\u001b[38;5;241m.\u001b[39mnumpy(), idx\u001b[38;5;241m.\u001b[39mnumpy())  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m neg_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/GNNenv/lib/python3.8/site-packages/torch_geometric/utils/_negative_sampling.py:314\u001b[0m, in \u001b[0;36msample\u001b[0;34m(population, k, device)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39marange(population, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/anaconda3/envs/GNNenv/lib/python3.8/random.py:383\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    381\u001b[0m             j \u001b[38;5;241m=\u001b[39m randbelow(n)\n\u001b[1;32m    382\u001b[0m         selected_add(j)\n\u001b[0;32m--> 383\u001b[0m         result[i] \u001b[38;5;241m=\u001b[39m \u001b[43mpopulation\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# graph = nx.read_graphml(\"aggregated_proteins_v30_subgraph.graphml\")       \n",
    "pipeline = GAEPipeline(in_channels=11, out_channels=30, sampling_method='random_walk')\n",
    "graph = pipeline.load_graph_from_pickle('combined_graph.pkl')\n",
    "pipeline.train(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baa0e36-419a-4aae-b81c-e5815683d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph = nx.read_graphml(\"aggregated_proteins_v70_subgraph.graphml\")\n",
    "pipeline = GAEPipeline(in_channels=11, out_channels=32, sampling_method='clusterGCN')\n",
    "graph = pipeline.load_graph_from_pickle('combined_graph.pkl')\n",
    "pipeline.train_clusterGCN(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6602aa2c-6f3d-40d6-9f61-1287794cf9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50164, 50164)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "Z = torch.load('clusterGCN_embedding.pt').detach().numpy()\n",
    "\n",
    "Z_normalized = Z / np.linalg.norm(Z, axis=1, keepdims=True)\n",
    "# Compute dot product\n",
    "similarity_matrix = np.dot(Z_normalized, Z_normalized.T)\n",
    "# print(similarity_matrix)\n",
    "\n",
    "# Apply sigmoid function to convert scores to probabilities\n",
    "adjacency_matrix_reconstructed = sigmoid(similarity_matrix)\n",
    "print(adjacency_matrix_reconstructed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264bc28c-85c5-4c09-810f-ea7f9f4cf8ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNNenv",
   "language": "python",
   "name": "gnnenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
