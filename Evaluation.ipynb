{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaed8f5d-1d6b-4cdc-891e-e57b5f8045f9",
   "metadata": {},
   "source": [
    "## Feature Selection and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac37288d-2ca7-40ee-bfc8-41ecf23f377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn import metrics\n",
    "\n",
    "def select_features_and_predict(train_data_path, target, processed_proteins, num_best_features, num_neighbors):\n",
    "    # Load data\n",
    "    train = pd.read_csv(train_data_path, index_col=0)\n",
    "\n",
    "    # Set up features\n",
    "    features = train.columns.tolist()\n",
    "    features.remove(target)\n",
    "    matched_set = processed_proteins.intersection(features)\n",
    "    features = list(matched_set)\n",
    "    print(\"Matched items:\", len(features))\n",
    "\n",
    "    best = []\n",
    "    max_acc = 0\n",
    "    all_features = features[:]  # Copy to retain the original features for neighbor selection\n",
    "\n",
    "    # Feature selection loop\n",
    "    while len(best) < num_best_features:\n",
    "        max_acc = 0\n",
    "        remaining_features = list(set(features) - set(best))\n",
    "        for new_column in remaining_features:\n",
    "            model = LogisticRegression()\n",
    "            if best:\n",
    "                model.fit(train[best + [new_column]], train[target])\n",
    "                target_predicted = model.predict(train[best + [new_column]])\n",
    "            else:\n",
    "                # Handle the case where best is empty (first iteration)\n",
    "                model.fit(train[[new_column]], train[target])\n",
    "                target_predicted = model.predict(train[[new_column]])\n",
    "            acc = metrics.accuracy_score(train[target], target_predicted)\n",
    "            if acc > max_acc:\n",
    "                max_acc = acc\n",
    "                max_column = new_column\n",
    "                \n",
    "        best.append(max_column)\n",
    "        features.remove(max_column)\n",
    "        print('Best columns:', best)\n",
    "        print('Accuracy:', max_acc)\n",
    "\n",
    "\n",
    "    return best\n",
    "\n",
    "# best_features = select_features_and_predict('data/train.csv', 'group', processed_proteins, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f14e0-7318-4b28-9284-2d7eada4e7a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "best_features = select_features_and_predict('data/train.csv', 'group', processed_proteins, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8446cad4-6154-4960-ba47-a64e9ff55439",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = map_names_to_tensor_indices(best_features, pipeline, existing_proteins_list)\n",
    "print(\"Index of the desired protein in the PyTorch Geometric tensor:\", indices)\n",
    "Z = torch.load('clusterGCN_embedding_relu_normalize.pt').detach().numpy()\n",
    "best_feature_embedding = Z[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845060e3-d04e-4079-8f51-c8098a8d463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec04f388-62e6-4fd7-be0a-c98fb53fb759",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feature_embedding = best_feature_embedding.reshape(best_feature_embedding.shape[0], -1)\n",
    "# best_feature_embedding = best_feature_embedding.reshape(1, -1)\n",
    "# best_feature_embedding = normalize(best_feature_embedding)\n",
    "knn = NearestNeighbors(n_neighbors=3, algorithm='auto', metric='euclidean')\n",
    "knn.fit(protein_embeddings)\n",
    "\n",
    "\n",
    "distances, indices = knn.kneighbors(protein_embeddings)\n",
    "print(\"Nearest Neighbors Indices:\", indices)\n",
    "print(\"Distances:\", distances)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# Calculate the mean similarity score using Euclidean distance\n",
    "similarity_scores = []\n",
    "\n",
    "for i, neighbors in enumerate(indices):\n",
    "    scores = []\n",
    "    for neighbor_index in neighbors:\n",
    "        if neighbor_index != i:\n",
    "            sim_score = 1 / (1 + euclidean_distances([protein_embeddings[i]], [protein_embeddings[neighbor_index]])[0, 0])\n",
    "            scores.append(sim_score)\n",
    "    mean_score = np.mean(scores)\n",
    "    similarity_scores.append(mean_score)\n",
    "\n",
    "average_similarity = np.mean(similarity_scores)\n",
    "print(f'Average Similarity Score (Euclidean): {average_similarity:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7969f2df-e9fa-430f-883a-67b739bdf586",
   "metadata": {},
   "source": [
    "## Load Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "582954fe-3812-4e23-813b-b330e833f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bio_df = pd.read_excel('data/expression_data.xlsx', engine='openpyxl')\n",
    "bio_df = bio_df.drop(bio_df.columns[0], axis=1)\n",
    "proteins = bio_df.columns.tolist()\n",
    "uniprot_to_reactome = pd.read_csv('data/MMU_Uniprot2Reactome.txt', sep='\\t')\n",
    "\n",
    "existing_proteins = uniprot_to_reactome[uniprot_to_reactome['V1'].isin(proteins)]['V1'].unique()\n",
    "\n",
    "existing_proteins_list = existing_proteins.tolist()\n",
    "# existing_proteins_list\n",
    "proteins_df = bio_df[existing_proteins_list[0:30]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f83930-30c4-42c7-b5c5-cd4d6bf0f318",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33228be2-fb67-4d05-9c48-3794ce1049e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_functions import *\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from train import GAEPipeline\n",
    "from train import GCNEncoder\n",
    "model_dir = 'latest_models_normalize/best_models_kmeans_k=3/64/'  # Directory where model files are saved\n",
    "result_dir = 'evaluation_results'\n",
    "n_clusters = 3 # Number of clusters for KMeans\n",
    "\n",
    "pipeline = GAEPipeline(in_channels=15, out_channels=32, sampling_method='clusterGCN', hidden_channels = 20, num_layers = 1, dropout_rate=0.05)\n",
    "graph = pipeline.load_graph_from_pickle('combined_graph_latest.pkl')\n",
    "\n",
    "data = pipeline.preprocess_graph(graph)\n",
    "models = generate_embeddings_from_models(model_dir, data, pipeline)\n",
    "protein_indices_in_pyg = get_protein_indices_in_pyg(graph, existing_proteins_list)\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=2)\n",
    "#agg_clustering = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "metrics, emd_metrics,  frobenius_norm_metrics = evaluate_embeddings(models, n_clusters,protein_indices_in_pyg, pipeline, kmeans)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb772ab-e36f-43f7-a9ed-eb0a33a0179f",
   "metadata": {},
   "source": [
    "## Graph Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c826e3-22b4-4e59-9a17-c16cd864e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = pipeline.load_graph_from_pickle('combined_graph_latest.pkl')\n",
    "\n",
    "\n",
    "# Number of Nodes (Vertices)\n",
    "num_nodes = G.number_of_nodes()\n",
    "\n",
    "# Number of Edges\n",
    "num_edges = G.number_of_edges()\n",
    "\n",
    "# Average Degree\n",
    "degrees = [degree for node, degree in G.degree()]\n",
    "average_degree = sum(degrees) / len(degrees)\n",
    "\n",
    "# Graph Density\n",
    "density = nx.density(G)\n",
    "\n",
    "# Diameter of Graph\n",
    "if nx.is_connected(G):\n",
    "    diameter = nx.diameter(G)\n",
    "else:\n",
    "    diameter = float('inf')  # or handle as appropriate\n",
    "\n",
    "\n",
    "# Is the Graph Directed?\n",
    "is_directed = G.is_directed()\n",
    "\n",
    "print(f\"Number of Nodes (Vertices): {num_nodes}\")\n",
    "print(f\"Number of Edges: {num_edges}\")\n",
    "print(f\"Average Degree: {average_degree}\")\n",
    "print(f\"Graph Density: {density}\")\n",
    "print(f\"Diameter of Graph: {diameter}\")\n",
    "print(f\"Is the Graph Directed?: {is_directed}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0d309e-0cb6-4f8d-ae44-7a8a24b0e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frobenius_norm_metrics[5])\n",
    "# df = pd.DataFrame(emd_metrics)\n",
    "# for index, row in df.iterrows():\n",
    "#     print(f\"EMD between {row['model1']} and {row['model2']}: {row['emd']:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNNenv",
   "language": "python",
   "name": "gnnenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
