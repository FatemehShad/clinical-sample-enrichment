{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaed8f5d-1d6b-4cdc-891e-e57b5f8045f9",
   "metadata": {},
   "source": [
    "## Feature Selection and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8446cad4-6154-4960-ba47-a64e9ff55439",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = select_features_and_predict('data/train.csv', 'group', processed_proteins, 4)\n",
    "indices = map_names_to_tensor_indices(best_features, pipeline, existing_proteins_list)\n",
    "print(\"Index of the desired protein in the PyTorch Geometric tensor:\", indices)\n",
    "Z = torch.load('clusterGCN_embedding_relu_normalize.pt').detach().numpy()\n",
    "best_feature_embedding = Z[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec04f388-62e6-4fd7-be0a-c98fb53fb759",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feature_embedding = best_feature_embedding.reshape(best_feature_embedding.shape[0], -1)\n",
    "# best_feature_embedding = best_feature_embedding.reshape(1, -1)\n",
    "# best_feature_embedding = normalize(best_feature_embedding)\n",
    "knn = NearestNeighbors(n_neighbors=3, algorithm='auto', metric='euclidean')\n",
    "knn.fit(protein_embeddings)\n",
    "distances, indices = knn.kneighbors(protein_embeddings)\n",
    "print(\"Nearest Neighbors Indices:\", indices)\n",
    "print(\"Distances:\", distances)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7969f2df-e9fa-430f-883a-67b739bdf586",
   "metadata": {},
   "source": [
    "## Load Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582954fe-3812-4e23-813b-b330e833f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bio_df = pd.read_excel('data/expression_data.xlsx', engine='openpyxl')\n",
    "bio_df = bio_df.drop(bio_df.columns[0], axis=1)\n",
    "proteins = bio_df.columns.tolist()\n",
    "uniprot_to_reactome = pd.read_csv('data/MMU_Uniprot2Reactome.txt', sep='\\t')\n",
    "\n",
    "existing_proteins = uniprot_to_reactome[uniprot_to_reactome['V1'].isin(proteins)]['V1'].unique()\n",
    "\n",
    "existing_proteins_list = existing_proteins.tolist()\n",
    "# existing_proteins_list\n",
    "proteins_df = bio_df[existing_proteins_list[0:30]]\n",
    "# print(existing_proteins_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1772d6c-d24d-4a73-b7bd-7e3d66578aee",
   "metadata": {},
   "source": [
    "## Functional Enrichment Analysis Without Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05fbcf0-993b-4eb4-b609-1d8129f52ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gprofiler as gp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Initialize g:Profiler client\n",
    "gp_client = gp.GProfiler(return_dataframe=True)\n",
    "\n",
    "# Perform g:Profiler analysis\n",
    "results = gp_client.profile(organism='mmusculus', query=existing_proteins_list)\n",
    "\n",
    "# Save results to a CSV file if you want to inspect or reuse them\n",
    "results.to_csv('gprofiler_results.csv', index=False)\n",
    "\n",
    "# Load the results\n",
    "results = pd.read_csv('gprofiler_results.csv')\n",
    "\n",
    "# Calculate the negative log10 of the p-values\n",
    "results['-log10(p_value)'] = -np.log10(results['p_value'])\n",
    "\n",
    "# Extract the necessary columns\n",
    "data = results[['source', 'name', '-log10(p_value)', 'term_size']]\n",
    "\n",
    "# Assign colors based on 'source'\n",
    "color_mapping = {\n",
    "    'GO:CC': 'green', 'GO:BP': 'orange', 'GO:MF': 'red', 'TF': 'magenta',\n",
    "    'REAC': 'blue', 'KEGG': 'purple', 'HP': 'brown', 'WP': 'cyan', 'CORUM': 'black'\n",
    "}\n",
    "data['color'] = data['source'].map(color_mapping)\n",
    "\n",
    "# Sort the data within each category based on term_size\n",
    "data = data.sort_values(by=['source', 'term_size'], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "# Count the number of terms in each category and sort categories by these counts\n",
    "category_counts = data['source'].value_counts()\n",
    "sorted_categories = category_counts.index\n",
    "\n",
    "# Create numeric categories for x-axis with increased spacing based on sorted order\n",
    "category_map = {category: i * 100 for i, category in enumerate(sorted_categories)}\n",
    "data['category_num'] = data['source'].map(category_map)\n",
    "\n",
    "# Add jitter to the x-axis within each category for better dispersion\n",
    "data['jitter'] = data.groupby('source').cumcount().apply(lambda x: np.random.uniform(-40, 40))\n",
    "\n",
    "# Adjust x-coordinate with jitter\n",
    "data['adjusted_x'] = data['category_num'] + data['jitter']\n",
    "\n",
    "# Scale the term_size for better visualization\n",
    "size_scaling_factor = 3000 / data['term_size'].max()  # Adjusted scaling factor for better visibility\n",
    "data['scaled_size'] = data['term_size'] * size_scaling_factor\n",
    "\n",
    "# Apply a minimum size threshold\n",
    "min_size = 50\n",
    "data['scaled_size'] = data['scaled_size'].apply(lambda x: max(x, min_size))\n",
    "\n",
    "# Set the style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(30, 10))\n",
    "\n",
    "# Draw the points with adjusted x-coordinates and scaled sizes\n",
    "plt.scatter(\n",
    "    x=data['adjusted_x'],\n",
    "    y=data['-log10(p_value)'],\n",
    "    s=data['scaled_size'],\n",
    "    c=data['color'],\n",
    "    alpha=0.6,\n",
    "    edgecolors='w',\n",
    "    linewidth=0.7\n",
    ")\n",
    "\n",
    "# Improve the plot aesthetics\n",
    "plt.xticks([category_map[cat] for cat in sorted_categories], [f'{cat} ({category_counts[cat]})' for cat in sorted_categories], rotation=45, ha='right', fontsize=24)\n",
    "plt.xlabel('Source', fontsize=30)\n",
    "plt.ylabel('-log10(p-value)', fontsize=30)\n",
    "plt.yticks(np.arange(0, 250, 20), fontsize=24)  # Set y-axis ticks to be in increments of 20\n",
    "plt.ylim(1, 200)  # Adjust the y-axis limit if needed\n",
    "# plt.title('g:Profiler Results', fontsize=36)\n",
    "\n",
    "# Add legends\n",
    "handles = [\n",
    "    plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=15, label=key) \n",
    "    for key, color in color_mapping.items()\n",
    "]\n",
    "# Custom legend for bubble sizes\n",
    "# sizes = [100, 500, 1000, 2000]\n",
    "# for size in sizes:\n",
    "#     handles.append(plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='gray', markersize=np.sqrt(size * size_scaling_factor), label=f'Term Size {size}'))\n",
    "\n",
    "# plt.legend(handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=20)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('gprofiler_scatter_plot_updated_with_sizes.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f83930-30c4-42c7-b5c5-cd4d6bf0f318",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33228be2-fb67-4d05-9c48-3794ce1049e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_functions import *\n",
    "from train import GAEPipeline\n",
    "from train import GCNEncoder\n",
    "model_dir = 'best'  # Directory where model files are saved\n",
    "result_dir = 'evaluation_results'\n",
    "n_clusters = 3 \n",
    "\n",
    "pipeline = GAEPipeline(in_channels=15, out_channels=32, sampling_method='clusterGCN', hidden_channels = 20, num_layers = 1, dropout_rate=0.05)\n",
    "graph = pipeline.load_graph_from_pickle('combined_graph_latest.pkl')\n",
    "\n",
    "data = pipeline.preprocess_graph(graph)\n",
    "models = generate_embeddings_from_models(model_dir, data, pipeline)\n",
    "protein_indices_in_pyg = get_protein_indices_in_pyg(graph, existing_proteins_list)\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=2)\n",
    "metrics, emd_metrics,  frobenius_norm_metrics = evaluate_embeddings(models, n_clusters,protein_indices_in_pyg, pipeline, kmeans)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNNenv",
   "language": "python",
   "name": "gnnenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
